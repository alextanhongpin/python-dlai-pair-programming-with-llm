{
    "cells": [
      {
        "cell_type": "markdown",
        "id": "9ee333b4-4b2e-4e45-8833-3a6e4782b46c",
        "metadata": {

        },
        "source": "# Pair Programming Scenarios\n"
      },
      {
        "cell_type": "markdown",
        "id": "279e9386-c8cd-4825-afcc-43e3191cad69",
        "metadata": {

        },
        "source": "#### Setup\nSet the MakerSuite API key with the provided helper function."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "39fa172d-0b5d-4fd1-9051-3d6f2e31730f",
        "metadata": {
          "height": 64,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "import os\nfrom utils import get_api_key\nimport google.generativeai as palm\nfrom google.api_core import client_options as client_options_lib\n\npalm.configure(\n    api_key=get_api_key(),\n    transport=\"rest\",\n    client_options=client_options_lib.ClientOptions(\n        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n    )\n)"
      },
      {
        "cell_type": "markdown",
        "id": "18775c71-13f5-49ff-ac4a-d34cb33afb0a",
        "metadata": {

        },
        "source": "#### Pick the model that generates text"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "a0ff7acb-6793-49b1-bf59-993c1a3bd612",
        "metadata": {
          "height": 64,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\nmodel_bison = models[0]\nmodel_bison"
      },
      {
        "cell_type": "markdown",
        "id": "8b6efbc6-7f98-4760-9ac0-3b513ef47d6a",
        "metadata": {

        },
        "source": "#### Helper function to call the PaLM API"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "008d0c81-4a13-42e2-b0e3-5fe65c56fc18",
        "metadata": {
          "height": 149,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "from google.api_core import retry\n@retry.Retry()\ndef generate_text(prompt, \n                  model=model_bison, \n                  temperature=0.0):\n    return palm.generate_text(prompt=prompt,\n                              model=model,\n                              temperature=temperature)"
      },
      {
        "cell_type": "markdown",
        "id": "00d25195-6e75-4617-a70c-f5486f9300bb",
        "metadata": {

        },
        "source": "### Scenario 1: Improve existing code\n- An LLM can help you rewrite your code in the way that's recommended for that particular language.\n- You can ask an LLM to rewrite your Python code in a way that is more 'Pythonic\"."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "7d76836a-7e57-4858-8ae5-0e2b6f6ae682",
        "metadata": {
          "height": 132,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nI don't think this code is the best way to do it in Python, can you help me?\n\n{question}\n\nPlease explain, in detail, what you did to improve it.\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "b98d292a-4c66-4fe0-94f9-09de640f075e",
        "metadata": {
          "height": 98,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "question = \"\"\"\ndef func_x(array)\n  for i in range(len(array)):\n    print(array[i])\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "c4944ff9-93c2-4a61-9ac0-54bff53d6ad4",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "b702c38c-a6ea-4eb2-978b-caf67e79c869",
        "metadata": {

        },
        "source": "#### Ask for multiple ways of rewriting your code"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "2f3cfe0b-2ec5-452a-bee6-ceb14cbd3f0a",
        "metadata": {
          "height": 132,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nI don't think this code is the best way to do it in Python, can you help me?\n\n{question}\n\nPlease explore multiple ways of solving the problem, and explain each.\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "564b598a-ff33-48f0-b58a-e1a355897a56",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "6eee86fb-5c10-4e49-a830-7fbe56de241a",
        "metadata": {

        },
        "source": "#### Paste markdown into a markdown cell\n\nIf the model outputs what looks like a table in markdown, you can copy-paste markdown into a markdown cell to make it easier to view:\n\nFor example:\n\n| Method | Pros | Cons |\n|---|---|---|\n| List comprehension | Concise | Can be difficult to read for complex code |\n| `enumerate()` | Easy to read | Requires an extra variable to store the index |\n| `map()` | Flexible | Requires a custom function to format the output |\n"
      },
      {
        "cell_type": "markdown",
        "id": "df910404-db59-4b9e-9477-408ccec9b7fc",
        "metadata": {

        },
        "source": "#### Ask the model to recommend one of the methods as most 'Pythonic'"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "b776a8cb-80c4-4e20-89dc-7bff2a350b9a",
        "metadata": {
          "height": 149,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nI don't think this code is the best way to do it in Python, can you help me?\n\n{question}\n\nPlease explore multiple ways of solving the problem, \nand tell me which is the most Pythonic\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "89521d8c-41c8-45fd-9ec3-5eea54c642a4",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "47315eff-85d3-45aa-bf14-a6f8ee1a43b9",
        "metadata": {

        },
        "source": "### Scenario 2: Simplify code\n- Ask the LLM to perform a code review.\n- Note that adding/removing newline characters may affect the LLM completion that gets output by the LLM."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "ef1b24b6-c20c-4e3b-9f80-1a6dea18fa24",
        "metadata": {
          "height": 149,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# option 1\nprompt_template = \"\"\"\nCan you please simplify this code for a linked list in Python?\n\n{question}\n\nExplain in detail what you did to modify it, and why.\n\"\"\""
      },
      {
        "cell_type": "markdown",
        "id": "f1c075dc-2f21-4ab5-99ed-798c08d20bad",
        "metadata": {

        },
        "source": "After you try option 1, you can modify it to look like option 2 (in this markdown cell) and see how it changes the completion.\n```Python\n# option 2\nprompt_template = \"\"\"\nCan you please simplify this code for a linked list in Python? \\n\nYou are an expert in Pythonic code.\n\n{question}\n\nPlease comment each line in detail, \\n\nand explain in detail what you did to modify it, and why.\n\"\"\"\n```"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "4663db7e-3b40-4776-9dc9-87fea5975ff1",
        "metadata": {
          "height": 319,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "question = \"\"\"\nclass Node:\n  def __init__(self, dataval=None):\n    self.dataval = dataval\n    self.nextval = None\n\nclass SLinkedList:\n  def __init__(self):\n    self.headval = None\n\nlist1 = SLinkedList()\nlist1.headval = Node(\"Mon\")\ne2 = Node(\"Tue\")\ne3 = Node(\"Wed\")\nlist1.headval.nextval = e2\ne2.nextval = e3\n\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "f954dcaf-3dfe-4265-b644-1bcbeead405b",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "2842f412-36f7-461f-a07f-eb95b345174d",
        "metadata": {

        },
        "source": "### Scenario 3: Write test cases\n\n- It may help to specify that you want the LLM to output \"in code\" to encourage it to write unit tests instead of just returning test cases in English."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "cf4c29c6-fe80-4aed-9e86-2daa6d862101",
        "metadata": {
          "height": 132,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nCan you please create test cases in code for this Python code?\n\n{question}\n\nExplain in detail what these test cases are designed to achieve.\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "3259b810-52b4-446b-971b-136df45d0f97",
        "metadata": {
          "height": 387,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# Note that the code I'm using here was output in the previous\n# section. Your output code may be different.\nquestion = \"\"\"\nclass Node:\n  def __init__(self, dataval=None):\n    self.dataval = dataval\n    self.nextval = None\n\nclass SLinkedList:\n  def __init__(self):\n    self.head = None\n\ndef create_linked_list(data):\n  head = Node(data[0])\n  for i in range(1, len(data)):\n    node = Node(data[i])\n    node.nextval = head\n    head = node\n  return head\n\nlist1 = create_linked_list([\"Mon\", \"Tue\", \"Wed\"])\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "ab46dc7e-393a-4ec3-a443-39b39437dd05",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "5b4e34dd-167c-4ce5-b0a6-20b1cf78f53c",
        "metadata": {

        },
        "source": "### Scenario 4: Make code more efficient\n- Improve runtime by potentially avoiding inefficient methods (such as ones that use recursion when not needed)."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "da4197f9-c6de-490d-a05e-6b604e0c0c40",
        "metadata": {
          "height": 132,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nCan you please make this code more efficient?\n\n{question}\n\nExplain in detail what you changed and why.\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "f653f4e0-c847-4639-8702-a9b16b161c24",
        "metadata": {
          "height": 489,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "question = \"\"\"\n# Returns index of x in arr if present, else -1\ndef binary_search(arr, low, high, x):\n    # Check base case\n    if high >= low:\n        mid = (high + low) // 2\n        if arr[mid] == x:\n            return mid\n        elif arr[mid] > x:\n            return binary_search(arr, low, mid - 1, x)\n        else:\n            return binary_search(arr, mid + 1, high, x)\n    else:\n        return -1\n\n# Test array\narr = [ 2, 3, 4, 10, 40 ]\nx = 10\n\n# Function call\nresult = binary_search(arr, 0, len(arr)-1, x)\n\nif result != -1:\n    print(\"Element is present at index\", str(result))\nelse:\n    print(\"Element is not present in array\")\n\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "c0150e46-ca82-420d-82ec-54eca96bd3d2",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question)\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "44a24541-c37b-48a0-bc71-a8323f0b9e2d",
        "metadata": {

        },
        "source": "#### Try out the LLM-generated code\n- If it uses `bisect`, you may first need to `import bisect`\n- Remember to check what the generated code is actually doing.  For instance, the code may work because it is calling a predefined function (such as `bisect`), even though the rest of the code is technically broken."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "ecde2b81-6e00-4977-b888-39e2f65a8d79",
        "metadata": {
          "height": 149,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# Paste the LLM-generated code to inspect and debug it\n\n\n\n\n\n\n"
      },
      {
        "cell_type": "markdown",
        "id": "7326a0cc-338b-4c83-9b57-3a84094f800a",
        "metadata": {

        },
        "source": "### Scenario 5: Debug your code"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "a10179f2-e09e-4c72-9991-a6f5d8418fc4",
        "metadata": {
          "height": 132,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt_template = \"\"\"\nCan you please help me to debug this code?\n\n{question}\n\nExplain in detail what you found and why it was a bug.\n\"\"\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "ed8384ba-3641-407e-add6-52efa2a43b48",
        "metadata": {
          "height": 625,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# I deliberately introduced a bug into this code! Let's see if the LLM can find it.\n# Note -- the model can't see this comment -- but the bug is in the\n# print function. There's a circumstance where nodes can be null, and trying\n# to print them would give a null error.\nquestion = \"\"\"\nclass Node:\n   def __init__(self, data):\n      self.data = data\n      self.next = None\n      self.prev = None\n\nclass doubly_linked_list:\n   def __init__(self):\n      self.head = None\n\n# Adding data elements\n   def push(self, NewVal):\n      NewNode = Node(NewVal)\n      NewNode.next = self.head\n      if self.head is not None:\n         self.head.prev = NewNode\n      self.head = NewNode\n\n# Print the Doubly Linked list in order\n   def listprint(self, node):\n       print(node.data),\n       last = node\n       node = node.next\n\ndllist = doubly_linked_list()\ndllist.push(12)\ndllist.push(8)\ndllist.push(62)\ndllist.listprint(dllist.head)\n\n\"\"\""
      },
      {
        "cell_type": "markdown",
        "id": "2e4874fd-722a-4b3d-8ca1-fab36c5e84f4",
        "metadata": {

        },
        "source": "Notice in this case that we are using the default temperature of `0.7` to generate the example that you're seeing in the lecture video.  \n- Since a temperature > 0 encourages more randomness in the LLM output, you may want to run this code a couple times to see what it outputs."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "360527f9-495e-41f4-a280-579f3643a36b",
        "metadata": {
          "height": 98,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(\n    prompt = prompt_template.format(question=question),\n    temperature = 0.7\n)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "82c9d0dc-c216-4ea5-8ccd-1f06094b9fad",
        "metadata": {

        },
        "source": "#### Reminder to check the code\nYou can use an  LLM to give you insights and check for blind spots, but remember to check that the generated code is doing what you want it to do."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "80634c53-72b8-43ee-8ac0-369fce8c0318",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": ""
      }
    ],
    "metadata": {
      "kernelspec": {
        "display_name": "Python 3 (ipykernel)",
        "language": "python",
        "name": "python3"
      },
      "language_info": {
        "codemirror_mode": {
          "name": "ipython",
          "version": 3
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython3",
        "version": "3.9.18"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
  }
