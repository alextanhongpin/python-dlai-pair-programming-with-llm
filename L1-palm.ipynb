{
    "cells": [
      {
        "cell_type": "markdown",
        "id": "7e80b742-0c2e-46d2-99e5-61f2982571e4",
        "metadata": {

        },
        "source": "# Lesson 1: Getting Started with PaLM"
      },
      {
        "cell_type": "markdown",
        "id": "b13b4dd3-3436-43f8-811c-262ed83d7767",
        "metadata": {

        },
        "source": "#### Setup\nSet the MakerSuite API key with the provided helper function."
      },
      {
        "cell_type": "code",
        "execution_count": 2,
        "id": "2db7275e-7ba3-482c-90a5-8d470dcca05c",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "from utils import get_api_key"
      },
      {
        "cell_type": "code",
        "execution_count": 3,
        "id": "30cd2bfb",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": "\r\n#!pip install python-dotenv\r\nimport os\r\nfrom dotenv import load_dotenv, find_dotenv\r\n\r\ndef get_api_key():\r\n    \r\n    _ = load_dotenv(find_dotenv()) # read local .env file\r\n    return os.getenv('GOOGLE_API_KEY')\r\n"
          }
        ],
        "source": "!cat utils.py"
      },
      {
        "cell_type": "markdown",
        "id": "a8be2f53-efa5-495f-808e-1e3189f0b73d",
        "metadata": {

        },
        "source": "In this classroom, we've installed the relevant libraries for you.\n\nIf you wanted to use the PaLM API on your own machine, you would first install the library:\n```Python\n!pip install -q google.generativeai\n```\nThe optional flag `-q` installs \"quietly\" without printing out details of the installation.\n"
      },
      {
        "cell_type": "code",
        "execution_count": 4,
        "id": "89a9a4b3-b338-4ed8-ac7b-a08143da5b63",
        "metadata": {
          "height": 200,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "import os\nimport google.generativeai as palm\nfrom google.api_core import client_options as client_options_lib\n\npalm.configure(\n    api_key=get_api_key(),\n    transport=\"rest\",\n    client_options=client_options_lib.ClientOptions(\n        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n    )\n)"
      },
      {
        "cell_type": "markdown",
        "id": "9648b897-5ad4-4caa-808d-97528c2fcf39",
        "metadata": {

        },
        "source": "### Explore the available models"
      },
      {
        "cell_type": "code",
        "execution_count": 5,
        "id": "77038a39-427c-4d1f-bc7e-e0692e8f6869",
        "metadata": {
          "height": 96,
          "trusted": false
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": "name: models/chat-bison-001\ndescription: Chat-optimized generative language model.\ngeneration methods:['generateMessage', 'countMessageTokens']\n\nname: models/text-bison-001\ndescription: Model targeted for text generation.\ngeneration methods:['generateText', 'countTextTokens', 'createTunedTextModel']\n\nname: models/embedding-gecko-001\ndescription: Obtain a distributed representation of a text.\ngeneration methods:['embedText']\n\n"
          }
        ],
        "source": "for m in palm.list_models():\n    print(f\"name: {m.name}\")\n    print(f\"description: {m.description}\")\n    print(f\"generation methods:{m.supported_generation_methods}\\n\")"
      },
      {
        "cell_type": "markdown",
        "id": "e8540099-fad0-4954-83a7-c2fba3f6d972",
        "metadata": {

        },
        "source": "#### Filter models by their supported generation methods\n- `generateText` is currently recommended for coding-related prompts.\n- `generateMessage` is optimized for multi-turn chats (dialogues) with an LLM."
      },
      {
        "cell_type": "code",
        "execution_count": 6,
        "id": "48e26d6a-02b9-4838-a0e6-d2e6a3ae042e",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [
          {
            "data": {
              "text/plain": "[Model(name='models/text-bison-001', base_model_id='', version='001', display_name='Text Bison', description='Model targeted for text generation.', input_token_limit=8196, output_token_limit=1024, supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'], temperature=0.7, top_p=0.95, top_k=40)]"
            },
            "execution_count": 6,
            "metadata": {

            },
            "output_type": "execute_result"
          }
        ],
        "source": "models = [m for m in palm.list_models() \n          if 'generateText' \n          in m.supported_generation_methods]\nmodels"
      },
      {
        "cell_type": "code",
        "execution_count": 7,
        "id": "4eb4fc7d-2a1a-43bc-9810-25e4db3b7cb7",
        "metadata": {
          "height": 47,
          "trusted": false
        },
        "outputs": [
          {
            "data": {
              "text/plain": "Model(name='models/text-bison-001', base_model_id='', version='001', display_name='Text Bison', description='Model targeted for text generation.', input_token_limit=8196, output_token_limit=1024, supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'], temperature=0.7, top_p=0.95, top_k=40)"
            },
            "execution_count": 7,
            "metadata": {

            },
            "output_type": "execute_result"
          }
        ],
        "source": "model_bison = models[0]\nmodel_bison"
      },
      {
        "cell_type": "markdown",
        "id": "18a24bff-ebe0-4fd3-93f6-c2aeef4d44f7",
        "metadata": {

        },
        "source": "#### helper function to generate text\n\n- The `@retry` decorator helps you to retry the API call if it fails.\n- We set the temperature to 0.0 so that the model returns the same output (completion) if given the same input (the prompt)."
      },
      {
        "cell_type": "code",
        "execution_count": 8,
        "id": "a93ff932-2a86-485a-adad-7f66e285aaf4",
        "metadata": {
          "height": 149,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "from google.api_core import retry\n@retry.Retry()\ndef generate_text(prompt,\n                  model=model_bison,\n                  temperature=0.0):\n    return palm.generate_text(prompt=prompt,\n                              model=model,\n                              temperature=temperature)"
      },
      {
        "cell_type": "markdown",
        "id": "aa756beb-7e70-4575-a27e-82b733b3d3b0",
        "metadata": {

        },
        "source": "#### Ask the LLM how to write some code\n\n"
      },
      {
        "cell_type": "code",
        "execution_count": 9,
        "id": "04080420-acd1-43a8-92bc-7d4c407a0154",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt = \"Show me how to iterate across a list in Python.\""
      },
      {
        "cell_type": "code",
        "execution_count": 10,
        "id": "32a354db-cb9b-4353-b777-4980256f4686",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(prompt)"
      },
      {
        "cell_type": "code",
        "execution_count": 11,
        "id": "ef2b1688-2eb7-465c-81cd-555d5b0a5a70",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [
          {
            "name": "stdout",
            "output_type": "stream",
            "text": "To iterate across a list in Python, you can use the `for` loop. The syntax is as follows:\n\n```python\nfor item in list:\n  # do something with item\n```\n\nFor example, the following code prints each item in the list `my_list`:\n\n```python\nmy_list = [\"a\", \"b\", \"c\"]\n\nfor item in my_list:\n  print(item)\n```\n\nOutput:\n\n```\na\nb\nc\n```\n\nYou can also use the `enumerate()` function to iterate over a list and get the index of each item. The syntax is as follows:\n\n```python\nfor index, item in enumerate(list):\n  # do something with index and item\n```\n\nFor example, the following code prints the index and value of each item in the list `my_list`:\n\n```python\nmy_list = [\"a\", \"b\", \"c\"]\n\nfor index, item in enumerate(my_list):\n  print(index, item)\n```\n\nOutput:\n\n```\n0 a\n1 b\n2 c\n```\n"
          }
        ],
        "source": "print(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "1400bcb5-bfe8-4192-809d-d95b21bf8422",
        "metadata": {

        },
        "source": "- Tip: The words \"show me\" tends to encourage the PaLM LLM to give more details and explanations compared to if you were to ask \"write code to ...\""
      },
      {
        "cell_type": "code",
        "execution_count": 12,
        "id": "6b813473-15de-4672-9097-57a3d04219d6",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "prompt = \"write code to iterate across a list in Python\""
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "3557557d-2b86-4755-a44f-8846e0035d3a",
        "metadata": {
          "height": 47,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "completion = generate_text(prompt)\nprint(completion.result)"
      },
      {
        "cell_type": "markdown",
        "id": "26114873-bb3c-4253-a679-4dda28af561c",
        "metadata": {

        },
        "source": "#### Try out the code\n- Try copy-pasting some of the generated code and running it in the notebook.\n- Remember to test out the LLM-generated code and debug it make sure it works as intended."
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "e2e76677-1b90-4ce4-a3b4-aae857e870f6",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# paste the LLM's code here\n\n\n"
      },
      {
        "cell_type": "markdown",
        "id": "3c649daa-781c-4c69-ac1b-d100e9747190",
        "metadata": {

        },
        "source": "#### Try asking your own coding question"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "c69b4929-ec4f-495c-a773-a92ce2c9b36c",
        "metadata": {
          "height": 81,
          "trusted": false
        },
        "outputs": [

        ],
        "source": "# Modify the prompt with your own question\nprompt = \"Show me how to [...]\"\n\ncompletion = generate_text(prompt)"
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "id": "c759d6a4-ed38-43fd-a588-1d62308a8746",
        "metadata": {
          "height": 30,
          "trusted": false
        },
        "outputs": [

        ],
        "source": ""
      },
      {
        "cell_type": "markdown",
        "id": "6a2b9e7a-4911-476d-9141-010224682d17",
        "metadata": {

        },
        "source": "#### Note about the API key\nWe've provided an API key for this classroom.  If you would like your own API key for your own projects, you can get one at [developers.generativeai.google](https://developers.generativeai.google/)"
      }
    ],
    "metadata": {
      "kernelspec": {
        "display_name": "Python 3 (ipykernel)",
        "language": "python",
        "name": "python3"
      },
      "language_info": {
        "codemirror_mode": {
          "name": "ipython",
          "version": 3
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython3",
        "version": "3.10.13"
      }
    },
    "nbformat": 4,
    "nbformat_minor": 5
  }
